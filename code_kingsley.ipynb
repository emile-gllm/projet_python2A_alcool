{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f15a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from sklearn.ensemble import StackingRegressor, RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6866978",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\7king\\AppData\\Local\\Temp\\ipykernel_40392\\540821597.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['COUNTRY'] = data['COUNTRY'].map(country_mapping)\n"
     ]
    }
   ],
   "source": [
    "#base deep seas\n",
    "#file_path2 = \"C:\\Users\\7king\\Desktop\\Projet Python\\projet_python_alcool\\Deepseas\\dp.xlsx\"\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\7king\\Desktop\\Projet Python\\projet_python_alcool\\Deepseas\\deep.csv\", sep=';', encoding='utf-8', low_memory=False, na_values=\" \", decimal=',')\n",
    "#df.describe() \n",
    "\n",
    "# Sélection des variables d'intérêt\n",
    "variables = [\"COUNTRY\",\"SD_1\", \"SD_2\", \"SD_4\",\"SD_6\", \"SD_7\", \n",
    "             \"SD_8\",\"SD_9\", \"SD_10\", \"sd_20month\" ,\"social_class\",\n",
    "             \"bsqf_alc\", \"f_1b\", \"cbsqf_beer\", \"cbsqf_spir\", \"cbsqf_wine\",\n",
    "              \"RSOD_2b\", \"CH_1\", \"WB_1\", \"WB_2\", \"WB_3\"]\n",
    "data = df[variables]\n",
    "\n",
    "# Mapping des codes pays aux noms complets\n",
    "country_mapping = {\n",
    "    10: 'Austria',\n",
    "    11: 'Belgium',\n",
    "    12: 'BosniaHerzegovina',\n",
    "    13: 'Bulgaria',\n",
    "    14: 'Catalunya',\n",
    "    15: 'Croatia',\n",
    "    16: 'Cyprus',\n",
    "    17: 'Czech Republic',\n",
    "    18: 'Denmark',\n",
    "    19: 'Estonia',\n",
    "    20: 'Finland',\n",
    "    21: 'France',\n",
    "    22: 'Germany',\n",
    "    23: 'Greece',\n",
    "    24: 'Hungary',\n",
    "    25: 'Iceland',\n",
    "    26: 'Ireland',\n",
    "    27: 'Italy',\n",
    "    28: 'Latvia',\n",
    "    29: 'Lithuania',\n",
    "    30: 'Luxembourg',\n",
    "    31: 'Malta',\n",
    "    32: 'Moldova',\n",
    "    33: 'Netherlands',\n",
    "    34: 'Norway',\n",
    "    35: 'Poland',\n",
    "    36: 'Portugal',\n",
    "    37: 'Romania',\n",
    "    38: 'Serbia',\n",
    "    39: 'Slovakia',\n",
    "    40: 'Slovenia',\n",
    "    41: 'Spain',\n",
    "    42: 'Sweden',\n",
    "    43: 'United Kingdom',\n",
    "}\n",
    "\n",
    "data['COUNTRY'] = data['COUNTRY'].map(country_mapping)\n",
    "data = data.dropna(subset=['bsqf_alc']) # Suppression des lignes où la variable cible est manquante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "188a8274",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertir_salaires_en_euro(df, col_salaire='sd_20month', col_pays='COUNTRY'):\n",
    "    \"\"\"\n",
    "    Convertit la colonne des salaires (monnaie locale) en Euros (base 2020)\n",
    "    en utilisant un dictionnaire de taux de change fixe.\n",
    "    La colonne originale est écrasée par les valeurs converties.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Définition des taux (1 Unité Locale = X Euros)\n",
    "    conversion_rates = {\n",
    "        # Zone Euro (Taux = 1)\n",
    "        'Austria': 1.0, 'Belgium': 1.0, 'Cyprus': 1.0, 'Finland': 1.0, 'France': 1.0,\n",
    "        'Germany': 1.0, 'Greece': 1.0, 'Ireland': 1.0, 'Italy': 1.0, 'Luxembourg': 1.0,\n",
    "        'Malta': 1.0, 'Netherlands': 1.0, 'Portugal': 1.0, 'Slovakia': 1.0, 'Slovenia': 1.0,\n",
    "        'Spain': 1.0, 'Catalunya': 1.0, 'Estonia': 1.0, 'Latvia': 1.0, 'Lithuania': 1.0,\n",
    "\n",
    "        # Hors Zone Euro\n",
    "        'BosniaHerzegovina': 1 / 1.956,  # BAM\n",
    "        'Bulgaria': 1 / 1.956,           # BGN\n",
    "        'Croatia': 1 / 7.430,            # HRK\n",
    "        'Denmark': 1 / 7.472,            # DKK\n",
    "        'Hungary': 1 / 330.50,           # HUF\n",
    "        'Iceland': 1 / 138.83,           # ISK\n",
    "        'Moldova': 1 / 19.33,            # MDL\n",
    "        'Norway': 1 / 9.855,             # NOK\n",
    "        'Poland': 1 / 4.256,             # PLN\n",
    "        'Romania': 1 / 4.779,            # RON\n",
    "        'Serbia': 1 / 117.85,            # RSD\n",
    "        'Sweden': 1 / 10.467,            # SEK\n",
    "        'Czech Republic': 1 / 25.40,     # CZK\n",
    "        'United Kingdom': 1 / 0.844,     # GBP\n",
    "        'Switzerland': 1 / 1.07,         # CHF (Ajout fréquent, à vérifier si présent)\n",
    "        'North Macedonia': 1 / 61.50,    # MKD\n",
    "        'Albania': 1 / 122.00,           # ALL\n",
    "        'Montenegro': 1.0,               # Utilise l'Euro\n",
    "        'Kosovo': 1.0,                   # Utilise l'Euro\n",
    "        'Ukraine': 1 / 26.50             # UAH (Approx 2020)\n",
    "    }\n",
    "\n",
    "    # 2. Création du vecteur de taux correspondant aux pays du DataFrame\n",
    "    # On utilise map() pour associer chaque ligne à son taux\n",
    "    taux_applicables = df[col_pays].map(conversion_rates)\n",
    "\n",
    "    # 4. Conversion et Remplacement\n",
    "    # On écrase l'ancienne colonne par la nouvelle valeur\n",
    "    df['sd_20month_EUR_2020'] = df[col_salaire] * taux_applicables\n",
    "    df.drop(columns=[col_salaire], inplace=True)\n",
    "\n",
    "    print(f\"Conversion terminée. La colonne '{col_salaire}' est maintenant exprimée en EUROS.\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "aafdb471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion terminée. La colonne 'sd_20month' est maintenant exprimée en EUROS.\n"
     ]
    }
   ],
   "source": [
    "data = convertir_salaires_en_euro(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "3a0cf8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputer_salaire_pays(df, colonne_salaire='sd_20month_EUR_2020', colonne_pays='COUNTRY', liste_pays = ['France', 'Iceland', 'Bulgaria', 'Poland']):\n",
    "    \"\"\"\n",
    "    Parcourt tous les pays de la base. Pour chaque pays, entraîne un modèle \n",
    "    spécifique sur les données de ce pays pour imputer ses valeurs manquantes.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    print(f\"Début de l'imputation pour {len(liste_pays)} pays...\\n\")\n",
    "\n",
    "    # On boucle sur chaque pays\n",
    "    for pays_cible in liste_pays:\n",
    "        \n",
    "        # Filtrage des données pour ce pays\n",
    "        # On utilise les indices pour pouvoir modifier le df original plus tard\n",
    "        indices_pays = df[df[colonne_pays] == pays_cible].index\n",
    "        df_pays = df.loc[indices_pays]\n",
    "        \n",
    "        # Séparer données connues (Train) et manquantes (Predict)\n",
    "        train_data = df_pays[df_pays[colonne_salaire].notna()]\n",
    "        predict_data = df_pays[df_pays[colonne_salaire].isna()]\n",
    "        \n",
    "        # Si aucune valeur manquante pour ce pays, on passe au suivant\n",
    "        if predict_data.empty:\n",
    "            continue\n",
    "            \n",
    "        # Préparation des variables (X et y)\n",
    "        # On exclut la cible et la colonne pays (car elle est constante ici)\n",
    "        features = df_pays.drop(columns=[colonne_salaire, colonne_pays])\n",
    "        \n",
    "       # Préparation des X et y pour l'entraînement\n",
    "        X = features.loc[train_data.index]\n",
    "        y = np.log(train_data[colonne_salaire])\n",
    "        \n",
    "        # 3. Évaluation des performances (Validation croisée simple)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        model = RandomForestRegressor(n_estimators=200, \n",
    "        max_depth=7,              \n",
    "        min_samples_leaf=5,       \n",
    "        max_features='sqrt',      \n",
    "        random_state=42)\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred_test = model.predict(X_test)\n",
    "        \n",
    "        print(f\"--- Performances du modèle pour {pays_cible} ---\")\n",
    "        print(f\"Score R² : {r2_score(y_test, y_pred_test):.4f}\")\n",
    "        print(f\"RMSE : {np.sqrt(mean_squared_error(y_test, y_pred_test)):.2f}\")\n",
    "        print(\"--------------------------------------------\\n\")\n",
    "        \n",
    "        \n",
    "        # 4. Imputation réelle\n",
    "        # Ré-entraînement sur toute la donnée disponible du pays\n",
    "        model.fit(X, y)\n",
    "        X_miss = features.loc[predict_data.index]\n",
    "        predictions = model.predict(X_miss)\n",
    "\n",
    "        \n",
    "        # Insertion des valeurs prédites dans le DataFrame original\n",
    "        df.loc[predict_data.index, colonne_salaire] = np.exp(predictions)\n",
    "\n",
    "    \n",
    "    print(\"\\n--- Imputation terminée pour tous les pays ---\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "18c4b6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputer_knn(df, cols_cibles=['RSOD_2b', 'SD_7'], col_pays='COUNTRY', n_voisins=5, liste_pays=['France', 'Iceland', 'Bulgaria', 'Poland']):\n",
    "    \"\"\"\n",
    "    Parcourt les pays et impute toutes les colonnes listées dans 'cols_cibles' \n",
    "    en utilisant KNN.\n",
    "    \"\"\"    \n",
    "\n",
    "    for pays_cible in liste_pays:\n",
    "        # 1. Isolation du pays\n",
    "        indices_pays = df[df[col_pays] == pays_cible].index\n",
    "        # On travaille sur une copie\n",
    "        df_pays = df.loc[indices_pays].copy()\n",
    "        \n",
    "        # Vérification rapide : Si TOUTES les colonnes cibles sont pleines, on passe\n",
    "        nb_na_total = df_pays[cols_cibles].isna().sum().sum()\n",
    "        if nb_na_total == 0:\n",
    "            continue\n",
    "            \n",
    "        # 2. Préparation des données (Tout sauf le pays)\n",
    "        # KNN a besoin de TOUTES les variables numériques pour trouver les voisins\n",
    "        features_cols = [c for c in df_pays.columns if c != col_pays]\n",
    "        X = df_pays[features_cols]\n",
    "        \n",
    "\n",
    "        # 3. Normalisation \n",
    "        scaler = StandardScaler()\n",
    "        X_scaled_values = scaler.fit_transform(X)\n",
    "        X_scaled = pd.DataFrame(X_scaled_values, columns=features_cols, index=X.index)\n",
    "\n",
    "        # 4. Imputation Globale \n",
    "        imputer = KNNImputer(n_neighbors=n_voisins)\n",
    "        X_imputed_values = imputer.fit_transform(X_scaled)\n",
    "        \n",
    "        # 5. Dé-normalisation\n",
    "        X_final_values = scaler.inverse_transform(X_imputed_values)\n",
    "        X_final = pd.DataFrame(X_final_values, columns=features_cols, index=X.index)\n",
    "        \n",
    "        # 6. Injection boucle par boucle \n",
    "        # On parcourt chaque colonne qu'on voulait réparer\n",
    "        for col in cols_cibles:\n",
    "            if col not in df_pays.columns:\n",
    "                continue\n",
    "                \n",
    "            # On ne touche qu'aux lignes qui étaient vides pour CETTE colonne\n",
    "            indices_manquants = df_pays[df_pays[col].isna()].index\n",
    "            \n",
    "            if len(indices_manquants) > 0:\n",
    "                # On récupère les valeurs calculées et on arrondit \n",
    "                valeurs_imputees = X_final.loc[indices_manquants, col].round()\n",
    "                \n",
    "                # Mise à jour dans le DataFrame Principal\n",
    "                df.loc[indices_manquants, col] = valeurs_imputees\n",
    "\n",
    "    print(f\"\\n Imputation terminée.\")\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
